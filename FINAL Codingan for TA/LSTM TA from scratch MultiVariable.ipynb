{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM from Scratch for TA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import *\n",
    "from numpy.random import *\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Function of Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predefined activation function and its derivative\n",
    "def Sigmoid(x): \n",
    "    return 1. / (1 + np.exp(-x))\n",
    "\n",
    "def dSigmoid(values): \n",
    "    return values*(1-values)\n",
    "\n",
    "def Tanh(x):\n",
    "    return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))\n",
    "\n",
    "def dtanh(values): \n",
    "    return 1. - values**2\n",
    "\n",
    "def rand_arr(a, b, *args): \n",
    "    seed(0)\n",
    "    return rand(*args)*(b - a) + a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define LSTM Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    def __init__(self, X_dim, y_dim, neuron):\n",
    "        \n",
    "        self.X_dim = X_dim \n",
    "        self.y_dim = y_dim\n",
    "        self.neuron = neuron\n",
    "        \n",
    "        #initiate weight\n",
    "        self.weight_f = rand_arr(-0.1, 0.1, neuron, X_dim + neuron)\n",
    "        self.weight_i = rand_arr(-0.1, 0.1, neuron, X_dim + neuron)\n",
    "        self.weight_g = rand_arr(-0.1, 0.1, neuron, X_dim + neuron) \n",
    "        self.weight_o = rand_arr(-0.1, 0.1, neuron, X_dim + neuron)\n",
    "        self.weight_out = rand_arr(-0.1, 0.1, y_dim, neuron)\n",
    "        \n",
    "        #initiate bias\n",
    "        self.bias_f = rand_arr(-0.1, 0.1, neuron) \n",
    "        self.bias_i = rand_arr(-0.1, 0.1, neuron) \n",
    "        self.bias_g = rand_arr(-0.1, 0.1, neuron) \n",
    "        self.bias_o = rand_arr(-0.1, 0.1, neuron)\n",
    "        self.bias_out = rand_arr(-0.1, 0.1, y_dim)\n",
    "    \n",
    "    def forward(self, inputs, outputs):\n",
    "        X = inputs \n",
    "        y = outputs\n",
    "        \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        #make list to save the values of every unit \n",
    "        self.X_concat = []\n",
    "        self.f = []\n",
    "        self.i = []\n",
    "        self.g = []\n",
    "        self.o = []\n",
    "        self.s = [zeros(self.neuron)] #first s input is 0\n",
    "        self.h = [zeros(self.neuron)] #first h input is 0\n",
    "        self.out = []\n",
    "        self.error = []\n",
    "        for i in range(len(inputs)):\n",
    "            #forward for every unit\n",
    "            X_concat = np.hstack((X[i],  self.h[i]))\n",
    "            self.X_concat.append(X_concat)\n",
    "            self.f.append(Sigmoid(self.weight_f@X_concat + self.bias_f))\n",
    "            self.i.append(Sigmoid(self.weight_i@X_concat + self.bias_i))\n",
    "            self.g.append(Tanh(self.weight_g@X_concat + self.bias_g))\n",
    "            self.o.append(Sigmoid(self.weight_o@X_concat + self.bias_o))\n",
    "            self.s.append(self.f[i]*self.s[i] + self.i[i]*self.g[i])\n",
    "            self.h.append(Tanh(self.s[i+1])*self.o[i])\n",
    "            self.out.append(self.weight_out@self.h[i+1] + self.bias_out)\n",
    "            self.error.append(abs(self.out[-1] - y[i]))\n",
    "        #show error\n",
    "        #print(np.array(self.error).mean())\n",
    "    \n",
    "    def backward(self, inputs, outputs):\n",
    "        self.diff_out = []\n",
    "        self.diff_h = []\n",
    "        self.diff_h_bottom = [zeros(self.neuron)]\n",
    "        self.diff_s_up = [zeros(self.neuron)]\n",
    "        self.diff_s = []\n",
    "        self.diff_o = []\n",
    "        self.diff_g = []\n",
    "        self.diff_i = []\n",
    "        self.diff_f = []\n",
    "        for i in range(len(inputs)-1,-1,-1):\n",
    "            #derivate of output\n",
    "            if i == len(inputs)-1:\n",
    "                self.diff_out  = [2*(self.out[i] - outputs[i])] + self.diff_out\n",
    "                self.diff_h = [self.diff_out[0]*dSigmoid(self.weight_out@self.h[i+1] + self.bias_out)*\n",
    "                               self.weight_out + self.diff_h_bottom[0]] + self.diff_h\n",
    "            else:\n",
    "                self.diff_h = [self.diff_h_bottom[0]] + self.diff_h\n",
    "            \n",
    "            \n",
    "            #derivative of gate/neural network operation\n",
    "            self.diff_s = [self.diff_h[0]*self.o[i]*dtanh(self.s[i+1]) + self.diff_s_up[0]] + self.diff_s\n",
    "            self.diff_o = [self.diff_h[0]*Tanh(self.s[i+1])] + self.diff_o\n",
    "            self.diff_g = [self.i[i]*self.diff_s[0]] + self.diff_g\n",
    "            self.diff_i = [self.g[i]*self.diff_s[0]] + self.diff_i\n",
    "            self.diff_f = [self.s[i]*self.diff_s[0]] + self.diff_f\n",
    "            \n",
    "            #derivative of concatenation of input dan previous output value\n",
    "            self.dX_concat = (self.diff_o[0].T*(dSigmoid(self.o[i]).reshape(self.neuron,1))).T@self.weight_o\n",
    "            self.dX_concat += (self.diff_g[0].T*(dSigmoid(self.g[i]).reshape(self.neuron,1))).T@self.weight_g\n",
    "            self.dX_concat += (self.diff_i[0].T*(dSigmoid(self.i[i]).reshape(self.neuron,1))).T@self.weight_i\n",
    "            self.dX_concat += (self.diff_f[0].T*(dSigmoid(self.f[i]).reshape(self.neuron,1))).T@self.weight_f\n",
    "            \n",
    "            #update value of long and short term memory\n",
    "            self.diff_h_bottom = [self.dX_concat[-1][self.X_dim:]] + self.diff_h_bottom\n",
    "            self.diff_s_up = [self.diff_s[0]*self.f[i]] + self.diff_s_up\n",
    "            \n",
    "    def update(self, alpha):\n",
    "        \n",
    "        #alpha \n",
    "        \n",
    "        #update everyweight and bias\n",
    "        self.weight_out -= alpha*self.diff_out[0].reshape(1,1)@self.h[1].T.reshape(1,self.neuron)\n",
    "        self.bias_out -= alpha*self.diff_out[0]\n",
    "        \n",
    "        self.weight_f -= alpha*(self.diff_f[0]*dSigmoid(self.weight_f@self.X_concat[0] + self.bias_f)).T@self.X_concat[0].reshape(1,self.X_dim + self.neuron)\n",
    "        self.bias_f -= alpha*(self.diff_f[0]*dSigmoid(self.weight_f@self.X_concat[0] + self.bias_f)).reshape(self.neuron,)\n",
    "        \n",
    "        self.weight_i -= alpha*(self.diff_i[0]*dSigmoid(self.weight_i@self.X_concat[0] + self.bias_i)).T@self.X_concat[0].reshape(1,self.X_dim + self.neuron)\n",
    "        self.bias_i -= alpha*(self.diff_i[0]*dSigmoid(self.weight_i@self.X_concat[0] + self.bias_i)).reshape(self.neuron,)\n",
    "        \n",
    "        self.weight_g -= alpha*(self.diff_g[0]*dSigmoid(self.weight_g@self.X_concat[0] + self.bias_g)).T@self.X_concat[0].reshape(1,self.X_dim + self.neuron)\n",
    "        self.bias_g -= alpha*(self.diff_g[0]*dSigmoid(self.weight_g@self.X_concat[0] + self.bias_g)).reshape(self.neuron,)\n",
    "        \n",
    "        self.weight_o -= alpha*(self.diff_o[0]*dSigmoid(self.weight_o@self.X_concat[0] + self.bias_o)).T.reshape(self.neuron,1)@self.X_concat[0].reshape(1,self.X_dim + self.neuron)\n",
    "        self.bias_o -= alpha*(self.diff_o[0]*dSigmoid(self.weight_o@self.X_concat[0] + self.bias_o)).reshape(self.neuron,)\n",
    "    \n",
    "    def predict(self, inputs, outputs):\n",
    "        X = inputs\n",
    "        y = outputs\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        #make list to save the values of every unit \n",
    "        self.X_concat = []\n",
    "        self.f = []\n",
    "        self.i = []\n",
    "        self.g = []\n",
    "        self.o = []\n",
    "        self.s = [zeros(self.neuron)] #first s input is 0\n",
    "        self.h = [zeros(self.neuron)] #first h input is 0\n",
    "        self.out = []\n",
    "        self.error = []\n",
    "        for i in range(len(inputs)):\n",
    "            #forward for every unit\n",
    "            X_concat = np.hstack((X[i],  self.h[i]))\n",
    "            self.X_concat.append(X_concat)\n",
    "            self.f.append(Sigmoid(self.weight_f@X_concat + self.bias_f))\n",
    "            self.i.append(Sigmoid(self.weight_i@X_concat + self.bias_i))\n",
    "            self.g.append(Tanh(self.weight_g@X_concat + self.bias_g))\n",
    "            self.o.append(Sigmoid(self.weight_o@X_concat + self.bias_o))\n",
    "            self.s.append(self.f[i]*self.s[i] + self.i[i]*self.g[i])\n",
    "            self.h.append(Tanh(self.s[i+1])*self.o[i])\n",
    "            self.out.append(self.weight_out@self.h[i+1] + self.bias_out)\n",
    "            self.error.append(abs(self.out[-1] - y[i]))\n",
    "        \n",
    "        return [self.out[-1][0],self.y[-1]]\n",
    "    \n",
    "    def show_progress(self):\n",
    "        return abs(self.y[-1][0] - self.out[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the Indicators Here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "epochs  = 10\n",
    "nc      = 10 #units\n",
    "\n",
    "#datasets\n",
    "name_dataset = 'UNVR-long'\n",
    "\n",
    "#column_dataset_obs = 'Close'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>7760.0</td>\n",
       "      <td>7760.0</td>\n",
       "      <td>7760.0</td>\n",
       "      <td>7760.0</td>\n",
       "      <td>6857.312500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>7840.0</td>\n",
       "      <td>7760.0</td>\n",
       "      <td>7765.0</td>\n",
       "      <td>6861.731445</td>\n",
       "      <td>5014500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>7770.0</td>\n",
       "      <td>8070.0</td>\n",
       "      <td>7770.0</td>\n",
       "      <td>8040.0</td>\n",
       "      <td>7104.741699</td>\n",
       "      <td>10642000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>8100.0</td>\n",
       "      <td>8110.0</td>\n",
       "      <td>8005.0</td>\n",
       "      <td>8110.0</td>\n",
       "      <td>7166.599121</td>\n",
       "      <td>10493500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>8060.0</td>\n",
       "      <td>8190.0</td>\n",
       "      <td>7965.0</td>\n",
       "      <td>8120.0</td>\n",
       "      <td>7175.434570</td>\n",
       "      <td>5400500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>2021-12-24</td>\n",
       "      <td>4090.0</td>\n",
       "      <td>4210.0</td>\n",
       "      <td>4080.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>4200.000000</td>\n",
       "      <td>11979500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>4230.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4210.0</td>\n",
       "      <td>4210.000000</td>\n",
       "      <td>7238100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>4210.0</td>\n",
       "      <td>4230.0</td>\n",
       "      <td>4180.0</td>\n",
       "      <td>4180.0</td>\n",
       "      <td>4180.000000</td>\n",
       "      <td>7006900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>4180.0</td>\n",
       "      <td>4190.0</td>\n",
       "      <td>4120.0</td>\n",
       "      <td>4120.0</td>\n",
       "      <td>4120.000000</td>\n",
       "      <td>9030700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>4130.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4110.0</td>\n",
       "      <td>4110.0</td>\n",
       "      <td>4110.000000</td>\n",
       "      <td>7633100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1262 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    Open    High     Low   Close    Adj Close    Volume\n",
       "0     2017-01-02  7760.0  7760.0  7760.0  7760.0  6857.312500         0\n",
       "1     2017-01-03  7800.0  7840.0  7760.0  7765.0  6861.731445   5014500\n",
       "2     2017-01-04  7770.0  8070.0  7770.0  8040.0  7104.741699  10642000\n",
       "3     2017-01-05  8100.0  8110.0  8005.0  8110.0  7166.599121  10493500\n",
       "4     2017-01-06  8060.0  8190.0  7965.0  8120.0  7175.434570   5400500\n",
       "...          ...     ...     ...     ...     ...          ...       ...\n",
       "1257  2021-12-24  4090.0  4210.0  4080.0  4200.0  4200.000000  11979500\n",
       "1258  2021-12-27  4200.0  4230.0  4170.0  4210.0  4210.000000   7238100\n",
       "1259  2021-12-28  4210.0  4230.0  4180.0  4180.0  4180.000000   7006900\n",
       "1260  2021-12-29  4180.0  4190.0  4120.0  4120.0  4120.000000   9030700\n",
       "1261  2021-12-30  4130.0  4170.0  4110.0  4110.0  4110.000000   7633100\n",
       "\n",
       "[1262 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Datasets/'+name_dataset+'.csv')\n",
    "# df.drop('Volume', inplace=True, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()\n",
    "new_df = df.drop([\"Date\",\"Adj Close\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7760.0</td>\n",
       "      <td>7760.0</td>\n",
       "      <td>7760.0</td>\n",
       "      <td>7760.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7800.0</td>\n",
       "      <td>7840.0</td>\n",
       "      <td>7760.0</td>\n",
       "      <td>7765.0</td>\n",
       "      <td>5014500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7770.0</td>\n",
       "      <td>8070.0</td>\n",
       "      <td>7770.0</td>\n",
       "      <td>8040.0</td>\n",
       "      <td>10642000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8100.0</td>\n",
       "      <td>8110.0</td>\n",
       "      <td>8005.0</td>\n",
       "      <td>8110.0</td>\n",
       "      <td>10493500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8060.0</td>\n",
       "      <td>8190.0</td>\n",
       "      <td>7965.0</td>\n",
       "      <td>8120.0</td>\n",
       "      <td>5400500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>4090.0</td>\n",
       "      <td>4210.0</td>\n",
       "      <td>4080.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>11979500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>4200.0</td>\n",
       "      <td>4230.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4210.0</td>\n",
       "      <td>7238100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>4210.0</td>\n",
       "      <td>4230.0</td>\n",
       "      <td>4180.0</td>\n",
       "      <td>4180.0</td>\n",
       "      <td>7006900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>4180.0</td>\n",
       "      <td>4190.0</td>\n",
       "      <td>4120.0</td>\n",
       "      <td>4120.0</td>\n",
       "      <td>9030700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>4130.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4110.0</td>\n",
       "      <td>4110.0</td>\n",
       "      <td>7633100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1262 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Open    High     Low   Close    Volume\n",
       "0     7760.0  7760.0  7760.0  7760.0         0\n",
       "1     7800.0  7840.0  7760.0  7765.0   5014500\n",
       "2     7770.0  8070.0  7770.0  8040.0  10642000\n",
       "3     8100.0  8110.0  8005.0  8110.0  10493500\n",
       "4     8060.0  8190.0  7965.0  8120.0   5400500\n",
       "...      ...     ...     ...     ...       ...\n",
       "1257  4090.0  4210.0  4080.0  4200.0  11979500\n",
       "1258  4200.0  4230.0  4170.0  4210.0   7238100\n",
       "1259  4210.0  4230.0  4180.0  4180.0   7006900\n",
       "1260  4180.0  4190.0  4120.0  4120.0   9030700\n",
       "1261  4130.0  4170.0  4110.0  4110.0   7633100\n",
       "\n",
       "[1262 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(new_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMax Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1262\n",
      "[[7.7600e+03 7.7600e+03 7.7600e+03 7.7600e+03 0.0000e+00]\n",
      " [7.8000e+03 7.8400e+03 7.7600e+03 7.7650e+03 5.0145e+06]\n",
      " [7.7700e+03 8.0700e+03 7.7700e+03 8.0400e+03 1.0642e+07]\n",
      " ...\n",
      " [4.2100e+03 4.2300e+03 4.1800e+03 4.1800e+03 7.0069e+06]\n",
      " [4.1800e+03 4.1900e+03 4.1200e+03 4.1200e+03 9.0307e+06]\n",
      " [4.1300e+03 4.1700e+03 4.1100e+03 4.1100e+03 7.6331e+06]]\n",
      "(1262, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.53261601, 0.50193548, 0.53658537, 0.53532609, 0.        ],\n",
       "       [0.53799597, 0.51225806, 0.53658537, 0.53600543, 0.01998575],\n",
       "       [0.533961  , 0.54193548, 0.53794038, 0.57336957, 0.04241466],\n",
       "       ...,\n",
       "       [0.05514459, 0.04645161, 0.05149051, 0.04891304, 0.02792664],\n",
       "       [0.05110962, 0.04129032, 0.04336043, 0.04076087, 0.03599268],\n",
       "       [0.04438467, 0.03870968, 0.04200542, 0.03940217, 0.03042242]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Get the number of rows in the data\n",
    "nrows = new_df.shape[0]\n",
    "print(nrows)\n",
    "# Convert the data to numpy values\n",
    "np_data_unscaled = np.array(new_df)\n",
    "print(np_data_unscaled)\n",
    "np_data = np.reshape(np_data_unscaled, (nrows, -1))\n",
    "print(np_data.shape)\n",
    "\n",
    "# Transform the data by scaling each feature to a range between 0 and 1\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "np_data_scaled = scaler.fit_transform(np_data_unscaled)\n",
    "\n",
    "np_data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# scaler = MinMaxScaler(feature_range=(0,1))\n",
    "# new_df = scaler.fit_transform(np.array(new_df).reshape(-1,1))\n",
    "# new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np_data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53261601, 0.50193548, 0.53658537, 0.53532609, 0.        ],\n",
       "       [0.53799597, 0.51225806, 0.53658537, 0.53600543, 0.01998575],\n",
       "       [0.533961  , 0.54193548, 0.53794038, 0.57336957, 0.04241466],\n",
       "       ...,\n",
       "       [0.05514459, 0.04645161, 0.05149051, 0.04891304, 0.02792664],\n",
       "       [0.05110962, 0.04129032, 0.04336043, 0.04076087, 0.03599268],\n",
       "       [0.04438467, 0.03870968, 0.04200542, 0.03940217, 0.03042242]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standarized the dataset\n",
    "N       = xs.shape[0]\n",
    "\n",
    "#hypreparameter\n",
    "Ts      = 1\n",
    "x_dim   = 1\n",
    "alpha   = 0.01 #learningrate\n",
    "\n",
    "xt      = xs[0:N-x_dim,:]\n",
    "\n",
    "for i in range(x_dim):\n",
    "    xt  = hstack((xt, xs[i+1:N-x_dim+i+1]))   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1261"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = int(len(new_df)*0.8)\n",
    "test_size = len(new_df)-training_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1009, 253)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = xt[:training_size, 0:x_dim]     \n",
    "y_train = xt[:training_size, x_dim:x_dim+1]  \n",
    "X_test = xt[-test_size:, 0:x_dim]     \n",
    "y_test = xt[-test_size:, x_dim:x_dim+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49096774],\n",
       "       [0.49419355],\n",
       "       [0.48774194],\n",
       "       [0.47483871],\n",
       "       [0.4683871 ],\n",
       "       [0.46516129],\n",
       "       [0.47483871],\n",
       "       [0.4683871 ],\n",
       "       [0.4683871 ],\n",
       "       [0.45548387],\n",
       "       [0.43612903],\n",
       "       [0.43935484],\n",
       "       [0.44903226],\n",
       "       [0.43935484],\n",
       "       [0.42967742],\n",
       "       [0.41354839],\n",
       "       [0.41032258],\n",
       "       [0.4716129 ],\n",
       "       [0.53290323],\n",
       "       [0.49096774],\n",
       "       [0.4683871 ],\n",
       "       [0.45548387],\n",
       "       [0.44580645],\n",
       "       [0.46516129],\n",
       "       [0.44903226],\n",
       "       [0.42645161],\n",
       "       [0.43290323],\n",
       "       [0.41677419],\n",
       "       [0.42      ],\n",
       "       [0.44580645],\n",
       "       [0.44580645],\n",
       "       [0.44903226],\n",
       "       [0.43612903],\n",
       "       [0.42645161],\n",
       "       [0.42322581],\n",
       "       [0.42645161],\n",
       "       [0.42645161],\n",
       "       [0.41677419],\n",
       "       [0.41677419],\n",
       "       [0.41677419],\n",
       "       [0.40064516],\n",
       "       [0.40387097],\n",
       "       [0.39419355],\n",
       "       [0.39741935],\n",
       "       [0.39096774],\n",
       "       [0.40387097],\n",
       "       [0.40387097],\n",
       "       [0.38451613],\n",
       "       [0.39096774],\n",
       "       [0.38774194],\n",
       "       [0.3716129 ],\n",
       "       [0.37806452],\n",
       "       [0.36516129],\n",
       "       [0.35548387],\n",
       "       [0.36516129],\n",
       "       [0.3683871 ],\n",
       "       [0.35870968],\n",
       "       [0.35225806],\n",
       "       [0.35225806],\n",
       "       [0.3716129 ],\n",
       "       [0.37483871],\n",
       "       [0.37806452],\n",
       "       [0.3716129 ],\n",
       "       [0.35870968],\n",
       "       [0.36516129],\n",
       "       [0.37483871],\n",
       "       [0.3683871 ],\n",
       "       [0.35225806],\n",
       "       [0.36516129],\n",
       "       [0.35548387],\n",
       "       [0.34258065],\n",
       "       [0.34580645],\n",
       "       [0.37806452],\n",
       "       [0.35548387],\n",
       "       [0.34580645],\n",
       "       [0.32      ],\n",
       "       [0.31677419],\n",
       "       [0.32645161],\n",
       "       [0.33290323],\n",
       "       [0.32322581],\n",
       "       [0.31354839],\n",
       "       [0.30064516],\n",
       "       [0.29419355],\n",
       "       [0.29419355],\n",
       "       [0.30064516],\n",
       "       [0.30064516],\n",
       "       [0.28451613],\n",
       "       [0.29096774],\n",
       "       [0.28774194],\n",
       "       [0.27483871],\n",
       "       [0.2683871 ],\n",
       "       [0.26193548],\n",
       "       [0.24580645],\n",
       "       [0.22645161],\n",
       "       [0.25870968],\n",
       "       [0.25225806],\n",
       "       [0.23935484],\n",
       "       [0.22967742],\n",
       "       [0.21677419],\n",
       "       [0.22645161],\n",
       "       [0.23290323],\n",
       "       [0.24258065],\n",
       "       [0.24258065],\n",
       "       [0.25548387],\n",
       "       [0.25548387],\n",
       "       [0.25548387],\n",
       "       [0.27483871],\n",
       "       [0.24903226],\n",
       "       [0.24580645],\n",
       "       [0.23612903],\n",
       "       [0.22      ],\n",
       "       [0.21032258],\n",
       "       [0.20064516],\n",
       "       [0.19096774],\n",
       "       [0.19419355],\n",
       "       [0.17806452],\n",
       "       [0.18129032],\n",
       "       [0.1683871 ],\n",
       "       [0.15548387],\n",
       "       [0.16516129],\n",
       "       [0.16193548],\n",
       "       [0.15870968],\n",
       "       [0.15225806],\n",
       "       [0.14903226],\n",
       "       [0.15870968],\n",
       "       [0.16516129],\n",
       "       [0.14580645],\n",
       "       [0.17806452],\n",
       "       [0.1716129 ],\n",
       "       [0.16516129],\n",
       "       [0.14903226],\n",
       "       [0.14322581],\n",
       "       [0.14064516],\n",
       "       [0.1316129 ],\n",
       "       [0.15548387],\n",
       "       [0.1716129 ],\n",
       "       [0.16193548],\n",
       "       [0.1683871 ],\n",
       "       [0.1716129 ],\n",
       "       [0.16193548],\n",
       "       [0.16516129],\n",
       "       [0.16516129],\n",
       "       [0.14064516],\n",
       "       [0.12258065],\n",
       "       [0.10709677],\n",
       "       [0.08645161],\n",
       "       [0.07612903],\n",
       "       [0.06967742],\n",
       "       [0.0683871 ],\n",
       "       [0.07741935],\n",
       "       [0.07096774],\n",
       "       [0.07483871],\n",
       "       [0.07870968],\n",
       "       [0.07096774],\n",
       "       [0.05806452],\n",
       "       [0.05935484],\n",
       "       [0.05032258],\n",
       "       [0.04903226],\n",
       "       [0.05290323],\n",
       "       [0.05032258],\n",
       "       [0.03225806],\n",
       "       [0.03483871],\n",
       "       [0.02967742],\n",
       "       [0.04      ],\n",
       "       [0.03870968],\n",
       "       [0.02580645],\n",
       "       [0.03354839],\n",
       "       [0.03612903],\n",
       "       [0.03096774],\n",
       "       [0.03612903],\n",
       "       [0.04903226],\n",
       "       [0.05548387],\n",
       "       [0.05419355],\n",
       "       [0.0516129 ],\n",
       "       [0.03612903],\n",
       "       [0.03612903],\n",
       "       [0.02967742],\n",
       "       [0.0283871 ],\n",
       "       [0.02709677],\n",
       "       [0.02580645],\n",
       "       [0.01935484],\n",
       "       [0.0116129 ],\n",
       "       [0.        ],\n",
       "       [0.02451613],\n",
       "       [0.02709677],\n",
       "       [0.02451613],\n",
       "       [0.01290323],\n",
       "       [0.        ],\n",
       "       [0.00645161],\n",
       "       [0.01806452],\n",
       "       [0.01548387],\n",
       "       [0.01935484],\n",
       "       [0.04129032],\n",
       "       [0.05548387],\n",
       "       [0.15225806],\n",
       "       [0.13677419],\n",
       "       [0.12645161],\n",
       "       [0.13677419],\n",
       "       [0.18129032],\n",
       "       [0.19741935],\n",
       "       [0.19741935],\n",
       "       [0.18129032],\n",
       "       [0.16516129],\n",
       "       [0.16516129],\n",
       "       [0.13935484],\n",
       "       [0.12645161],\n",
       "       [0.11225806],\n",
       "       [0.10580645],\n",
       "       [0.09548387],\n",
       "       [0.08774194],\n",
       "       [0.08774194],\n",
       "       [0.07741935],\n",
       "       [0.08258065],\n",
       "       [0.08516129],\n",
       "       [0.07870968],\n",
       "       [0.07741935],\n",
       "       [0.07741935],\n",
       "       [0.07225806],\n",
       "       [0.10580645],\n",
       "       [0.11225806],\n",
       "       [0.09806452],\n",
       "       [0.09032258],\n",
       "       [0.0916129 ],\n",
       "       [0.08645161],\n",
       "       [0.10322581],\n",
       "       [0.12516129],\n",
       "       [0.1316129 ],\n",
       "       [0.12903226],\n",
       "       [0.12774194],\n",
       "       [0.12387097],\n",
       "       [0.10709677],\n",
       "       [0.10064516],\n",
       "       [0.08774194],\n",
       "       [0.06064516],\n",
       "       [0.06064516],\n",
       "       [0.04903226],\n",
       "       [0.05548387],\n",
       "       [0.06193548],\n",
       "       [0.06451613],\n",
       "       [0.07225806],\n",
       "       [0.07225806],\n",
       "       [0.06322581],\n",
       "       [0.06451613],\n",
       "       [0.05806452],\n",
       "       [0.04774194],\n",
       "       [0.03741935],\n",
       "       [0.04      ],\n",
       "       [0.03354839],\n",
       "       [0.03225806],\n",
       "       [0.04387097],\n",
       "       [0.04645161],\n",
       "       [0.04645161],\n",
       "       [0.04129032]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- 1 -------------\n",
      "0.08985839442542537\n",
      "------------- 2 -------------\n",
      "0.08981778768745734\n",
      "------------- 3 -------------\n",
      "0.08977720524952713\n",
      "------------- 4 -------------\n",
      "0.08973664983463546\n",
      "------------- 5 -------------\n",
      "0.0896961240824531\n",
      "------------- 6 -------------\n",
      "0.08965563056229947\n",
      "------------- 7 -------------\n",
      "0.08961517176530295\n",
      "------------- 8 -------------\n",
      "0.0895747500967086\n",
      "------------- 9 -------------\n",
      "0.08953436786833936\n",
      "------------- 10 -------------\n",
      "0.08949402729121676\n"
     ]
    }
   ],
   "source": [
    "me = LSTM(x_dim,1,nc)\n",
    "for i in range(epochs):\n",
    "    print('-------------',i+1,'-------------')\n",
    "    for j in range(X_train.shape[0]-Ts):\n",
    "        me.forward(X_train[j:j+Ts],y_train[j:j+Ts])\n",
    "        me.backward(X_train[j:j+Ts],y_train[j:j+Ts])\n",
    "        me.update(alpha)\n",
    "    hehe = []\n",
    "    for j in range(X_test.shape[0]-Ts):\n",
    "        me.forward(X_test[j:j+Ts],y_test[j:j+Ts])\n",
    "        me.backward(X_test[j:j+Ts],y_test[j:j+Ts])\n",
    "        me.update(alpha)\n",
    "        hehe.append(me.show_progress())    \n",
    "    print(np.array(hehe).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09579386, 0.49096774],\n",
       "       [0.09586221, 0.49419355],\n",
       "       [0.09587196, 0.48774194],\n",
       "       [0.0958427 , 0.47483871],\n",
       "       [0.09582317, 0.4683871 ],\n",
       "       [0.09580363, 0.46516129],\n",
       "       [0.09580363, 0.47483871],\n",
       "       [0.09580363, 0.4683871 ],\n",
       "       [0.09581341, 0.4683871 ],\n",
       "       [0.0957743 , 0.45548387],\n",
       "       [0.09570574, 0.43612903],\n",
       "       [0.09572534, 0.43935484],\n",
       "       [0.09569593, 0.44903226],\n",
       "       [0.09572534, 0.43935484],\n",
       "       [0.09570574, 0.42967742],\n",
       "       [0.09563701, 0.41354839],\n",
       "       [0.09562718, 0.41032258],\n",
       "       [0.0956075 , 0.4716129 ],\n",
       "       [0.09594013, 0.53290323],\n",
       "       [0.09586221, 0.49096774],\n",
       "       [0.09578408, 0.4683871 ],\n",
       "       [0.0957743 , 0.45548387],\n",
       "       [0.09573514, 0.44580645],\n",
       "       [0.09573514, 0.46516129],\n",
       "       [0.09575473, 0.44903226],\n",
       "       [0.09566648, 0.42645161],\n",
       "       [0.09565666, 0.43290323],\n",
       "       [0.09558782, 0.41677419],\n",
       "       [0.09566648, 0.42      ],\n",
       "       [0.09566648, 0.44580645],\n",
       "       [0.09572534, 0.44580645],\n",
       "       [0.09575473, 0.44903226],\n",
       "       [0.09571554, 0.43612903],\n",
       "       [0.09568612, 0.42645161],\n",
       "       [0.09568612, 0.42322581],\n",
       "       [0.09569593, 0.42645161],\n",
       "       [0.09569593, 0.42645161],\n",
       "       [0.09566648, 0.41677419],\n",
       "       [0.09562718, 0.41677419],\n",
       "       [0.09565666, 0.41677419],\n",
       "       [0.09561734, 0.40064516],\n",
       "       [0.09561734, 0.40387097],\n",
       "       [0.09558782, 0.39419355],\n",
       "       [0.09556812, 0.39741935],\n",
       "       [0.09556812, 0.39096774],\n",
       "       [0.09552867, 0.40387097],\n",
       "       [0.09562718, 0.40387097],\n",
       "       [0.09555826, 0.38451613],\n",
       "       [0.09555826, 0.39096774],\n",
       "       [0.09557797, 0.38774194],\n",
       "       [0.09550893, 0.3716129 ],\n",
       "       [0.0955484 , 0.37806452],\n",
       "       [0.09550893, 0.36516129],\n",
       "       [0.09545952, 0.35548387],\n",
       "       [0.09545952, 0.36516129],\n",
       "       [0.09550893, 0.3683871 ],\n",
       "       [0.09545952, 0.35870968],\n",
       "       [0.09544963, 0.35225806],\n",
       "       [0.09542983, 0.35225806],\n",
       "       [0.09546941, 0.3716129 ],\n",
       "       [0.09552867, 0.37483871],\n",
       "       [0.09549906, 0.37806452],\n",
       "       [0.0955188 , 0.3716129 ],\n",
       "       [0.09546941, 0.35870968],\n",
       "       [0.09548918, 0.36516129],\n",
       "       [0.09546941, 0.37483871],\n",
       "       [0.09550893, 0.3683871 ],\n",
       "       [0.09546941, 0.35225806],\n",
       "       [0.09545952, 0.36516129],\n",
       "       [0.0954793 , 0.35548387],\n",
       "       [0.09542983, 0.34258065],\n",
       "       [0.09541993, 0.34580645],\n",
       "       [0.09543973, 0.37806452],\n",
       "       [0.09546941, 0.35548387],\n",
       "       [0.09542983, 0.34580645],\n",
       "       [0.09537037, 0.32      ],\n",
       "       [0.09533066, 0.31677419],\n",
       "       [0.09535052, 0.32645161],\n",
       "       [0.0953902 , 0.33290323],\n",
       "       [0.09537037, 0.32322581],\n",
       "       [0.09535052, 0.31354839],\n",
       "       [0.0952909 , 0.30064516],\n",
       "       [0.09527099, 0.29419355],\n",
       "       [0.0952909 , 0.29419355],\n",
       "       [0.09526104, 0.30064516],\n",
       "       [0.09531078, 0.30064516],\n",
       "       [0.09524111, 0.28451613],\n",
       "       [0.09527099, 0.29096774],\n",
       "       [0.09525108, 0.28774194],\n",
       "       [0.09523115, 0.27483871],\n",
       "       [0.09519125, 0.2683871 ],\n",
       "       [0.0951313 , 0.26193548],\n",
       "       [0.0951313 , 0.24580645],\n",
       "       [0.09505118, 0.22645161],\n",
       "       [0.09505118, 0.25870968],\n",
       "       [0.09509127, 0.25225806],\n",
       "       [0.09509127, 0.23935484],\n",
       "       [0.09509127, 0.22967742],\n",
       "       [0.09505118, 0.21677419],\n",
       "       [0.09501104, 0.22645161],\n",
       "       [0.09509127, 0.23290323],\n",
       "       [0.09509127, 0.24258065],\n",
       "       [0.0951313 , 0.24258065],\n",
       "       [0.0951213 , 0.25548387],\n",
       "       [0.09517128, 0.25548387],\n",
       "       [0.0951413 , 0.25548387],\n",
       "       [0.09523115, 0.27483871],\n",
       "       [0.0951513 , 0.24903226],\n",
       "       [0.0951413 , 0.24580645],\n",
       "       [0.09509127, 0.23612903],\n",
       "       [0.09506121, 0.22      ],\n",
       "       [0.09502108, 0.21032258],\n",
       "       [0.0949809 , 0.20064516],\n",
       "       [0.09495073, 0.19096774],\n",
       "       [0.09497085, 0.19419355],\n",
       "       [0.09492053, 0.17806452],\n",
       "       [0.0948903 , 0.18129032],\n",
       "       [0.09490038, 0.1683871 ],\n",
       "       [0.09486004, 0.15548387],\n",
       "       [0.09474883, 0.16516129],\n",
       "       [0.09487013, 0.16193548],\n",
       "       [0.09484995, 0.15870968],\n",
       "       [0.09482571, 0.15225806],\n",
       "       [0.09483985, 0.14903226],\n",
       "       [0.09483985, 0.15870968],\n",
       "       [0.09487013, 0.16516129],\n",
       "       [0.09482975, 0.14580645],\n",
       "       [0.09480954, 0.17806452],\n",
       "       [0.09491046, 0.1716129 ],\n",
       "       [0.0948903 , 0.16516129],\n",
       "       [0.09481358, 0.14903226],\n",
       "       [0.09481358, 0.14322581],\n",
       "       [0.09480954, 0.14064516],\n",
       "       [0.09476908, 0.1316129 ],\n",
       "       [0.09478931, 0.15548387],\n",
       "       [0.09487013, 0.1716129 ],\n",
       "       [0.09487013, 0.16193548],\n",
       "       [0.09483985, 0.1683871 ],\n",
       "       [0.0948903 , 0.1716129 ],\n",
       "       [0.09487013, 0.16193548],\n",
       "       [0.09486004, 0.16516129],\n",
       "       [0.09488022, 0.16516129],\n",
       "       [0.09481358, 0.14064516],\n",
       "       [0.09474883, 0.12258065],\n",
       "       [0.09470828, 0.10709677],\n",
       "       [0.09462704, 0.08645161],\n",
       "       [0.09460669, 0.07612903],\n",
       "       [0.09458226, 0.06967742],\n",
       "       [0.09451294, 0.0683871 ],\n",
       "       [0.09458634, 0.07741935],\n",
       "       [0.09458634, 0.07096774],\n",
       "       [0.09455781, 0.07483871],\n",
       "       [0.09460262, 0.07870968],\n",
       "       [0.09459041, 0.07096774],\n",
       "       [0.09454558, 0.05806452],\n",
       "       [0.0945415 , 0.05935484],\n",
       "       [0.09451702, 0.05032258],\n",
       "       [0.0945211 , 0.04903226],\n",
       "       [0.09449252, 0.05290323],\n",
       "       [0.09452518, 0.05032258],\n",
       "       [0.09445982, 0.03225806],\n",
       "       [0.09445573, 0.03483871],\n",
       "       [0.09444755, 0.02967742],\n",
       "       [0.094468  , 0.04      ],\n",
       "       [0.09449252, 0.03870968],\n",
       "       [0.09444755, 0.02580645],\n",
       "       [0.09443937, 0.03354839],\n",
       "       [0.094468  , 0.03612903],\n",
       "       [0.09445164, 0.03096774],\n",
       "       [0.094468  , 0.03612903],\n",
       "       [0.09449252, 0.04903226],\n",
       "       [0.0945211 , 0.05548387],\n",
       "       [0.09452518, 0.05419355],\n",
       "       [0.09452518, 0.0516129 ],\n",
       "       [0.09446391, 0.03612903],\n",
       "       [0.09447617, 0.03612903],\n",
       "       [0.09445573, 0.02967742],\n",
       "       [0.09444346, 0.0283871 ],\n",
       "       [0.09444346, 0.02709677],\n",
       "       [0.09444346, 0.02580645],\n",
       "       [0.09442709, 0.01935484],\n",
       "       [0.09440251, 0.0116129 ],\n",
       "       [0.09436562, 0.        ],\n",
       "       [0.09435742, 0.02451613],\n",
       "       [0.09444346, 0.02709677],\n",
       "       [0.09443937, 0.02451613],\n",
       "       [0.09441071, 0.01290323],\n",
       "       [0.09436562, 0.        ],\n",
       "       [0.094341  , 0.00645161],\n",
       "       [0.09439432, 0.01806452],\n",
       "       [0.09439432, 0.01548387],\n",
       "       [0.09437382, 0.01935484],\n",
       "       [0.0944148 , 0.04129032],\n",
       "       [0.09450477, 0.05548387],\n",
       "       [0.09454558, 0.15225806],\n",
       "       [0.09478122, 0.13677419],\n",
       "       [0.09473262, 0.12645161],\n",
       "       [0.09476098, 0.13677419],\n",
       "       [0.09480954, 0.18129032],\n",
       "       [0.0949306 , 0.19741935],\n",
       "       [0.09496079, 0.19741935],\n",
       "       [0.09492053, 0.18129032],\n",
       "       [0.09487013, 0.16516129],\n",
       "       [0.0948903 , 0.16516129],\n",
       "       [0.09480954, 0.13935484],\n",
       "       [0.09476908, 0.12645161],\n",
       "       [0.09465956, 0.11225806],\n",
       "       [0.09468799, 0.10580645],\n",
       "       [0.09463924, 0.09548387],\n",
       "       [0.09461076, 0.08774194],\n",
       "       [0.09462704, 0.08774194],\n",
       "       [0.09460669, 0.07741935],\n",
       "       [0.09462297, 0.08258065],\n",
       "       [0.09461076, 0.08516129],\n",
       "       [0.09461076, 0.07870968],\n",
       "       [0.09460669, 0.07741935],\n",
       "       [0.09461076, 0.07741935],\n",
       "       [0.09459448, 0.07225806],\n",
       "       [0.09459041, 0.10580645],\n",
       "       [0.09470423, 0.11225806],\n",
       "       [0.09467987, 0.09806452],\n",
       "       [0.09463111, 0.09032258],\n",
       "       [0.0946555 , 0.0916129 ],\n",
       "       [0.0946189 , 0.08645161],\n",
       "       [0.09462704, 0.10322581],\n",
       "       [0.09469205, 0.12516129],\n",
       "       [0.09476503, 0.1316129 ],\n",
       "       [0.09477717, 0.12903226],\n",
       "       [0.09476503, 0.12774194],\n",
       "       [0.09475288, 0.12387097],\n",
       "       [0.09470828, 0.10709677],\n",
       "       [0.09466769, 0.10064516],\n",
       "       [0.0946189 , 0.08774194],\n",
       "       [0.09454966, 0.06064516],\n",
       "       [0.09454558, 0.06064516],\n",
       "       [0.09451702, 0.04903226],\n",
       "       [0.0945211 , 0.05548387],\n",
       "       [0.09454558, 0.06193548],\n",
       "       [0.09454558, 0.06451613],\n",
       "       [0.09457412, 0.07225806],\n",
       "       [0.09458634, 0.07225806],\n",
       "       [0.09456597, 0.06322581],\n",
       "       [0.0945415 , 0.06451613],\n",
       "       [0.0945415 , 0.05806452],\n",
       "       [0.0944966 , 0.04774194],\n",
       "       [0.09448435, 0.03741935],\n",
       "       [0.09448435, 0.04      ],\n",
       "       [0.09446391, 0.03354839],\n",
       "       [0.09444755, 0.03225806],\n",
       "       [0.09445982, 0.04387097],\n",
       "       [0.09450477, 0.04645161],\n",
       "       [0.09450886, 0.04645161]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "out = []\n",
    "for j in range(X_test.shape[0]-Ts):\n",
    "    out.append(me.predict(X_test[j:j+Ts],y_test[j:j+Ts]))\n",
    "\n",
    "new_output = []\n",
    "for k in out:\n",
    "    real_val = k[0].tolist()\n",
    "    predict_val=k[1][0].tolist()\n",
    "    new_output.append(real_val)\n",
    "    new_output.append(predict_val)\n",
    "    \n",
    "new_output = np.reshape(new_output, (-1,2))\n",
    "new_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1 into shape (1,5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [151]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m new_output:\n\u001b[1;32m----> 2\u001b[0m     y_test_unscaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform(\u001b[43ml\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      3\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform(l[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 1 into shape (1,5)"
     ]
    }
   ],
   "source": [
    "for l in new_output:\n",
    "    y_test_unscaled = scaler.inverse_transform(l[0].reshape(1, 5))\n",
    "    y_pred = scaler.inverse_transform(l[1].reshape(1, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report Performance of LSTM Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse = mean_squared_error(y, predictions)\n",
    "# print('MSE: '+str(mse))\n",
    "print('epoch: ' + str(epochs))\n",
    "print('units: ' + str(nc))\n",
    "\n",
    "rmse = math.sqrt(mean_squared_error(np.array(out)[:,1], np.array(out)[:,0]))\n",
    "print('RMSE: '+ str(\"{:.2f}\".format(rmse)))\n",
    "mae = mean_absolute_error(np.array(out)[:,1], np.array(out)[:,0])\n",
    "print('MAE: '+ str(\"{:.2f}\".format(mae)))\n",
    "mape = mean_absolute_percentage_error(np.array(out)[:,1], np.array(out)[:,0])\n",
    "print('MAPE: '+ str(\"{:.2f}\".format(mape*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Test Data the Prediction and Real Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.array(out)[:,1], color = 'red', label = 'Real Stock Price')\n",
    "plt.plot(np.array(out)[:,0], color = 'blue', label = 'Predicted Stock Price')\n",
    "plt.title(name_dataset +' Term Stock Prediction, epochs: '+ str(epochs) +'; units: '+str(nc))\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel(name_dataset +' Stock Price '+ column_dataset_obs)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save as a new Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_price = np.array(out)[:,1]\n",
    "close_lstm = np.array(out)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = {'real_price': real_price,\n",
    "            'Close_LSTM': close_lstm}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_data = pd.DataFrame(new_data, columns = ['real_price', 'Close_LSTM'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_data.to_csv('../Datasets/dataset after prediction/'+name_dataset\n",
    "                   +'_LSTM_'+ str(epochs) +'_'+ str(nc) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
